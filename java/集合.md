fail-fast和fail-safe在遍历一个集合时候（用Iterator），对于线程不安全的类，并发情况下可能会出现fail-fast情况；而线程安全的类，可能出现fail-safe的情况。fail-fast机制：在遍历时（用Iterator），如果集合对象的结构被修改了，就会抛出ConcurrentModificationExcetion异常。例如你用迭代器在遍历一个list，这时候你调用list.remove会抛异常fail-safe机制：在遍历时（用Iterator），不是直接在集合内容上访问的，而是先复制原有集合内容，在拷贝的集合上进行遍历ArrayList、LinkedList、Vector、SynchronizedList、CopyOnWriteArrayListArrayList 和 LinkedList 和 Vector 的区别
* ArrayList 是一个可改变大小的数组，当更多的元素加入到 ArrayList 中时，其大小将会动态地增长，内部的元素可以直接通过 get 与 set 方法进行访问，add 和 remove 的性能弱，get 和 set 性能强，默认情况下 ArrayList 的初始容量非常小,所以如果可以预估数据量的话,分配一个较大的初始值属于最佳实践,这样可以减少调整大小的开销
* LinkedList 是一个双向链表，因为是链表所以不需要扩容。add 和 remove 的性能强，get 和 set 性能弱。LinkedList 还实现了 Queue和Deque（双端队列同时也实现了栈方法，注意pop时候如果为空会报错） 接口，该接口比 List 提供了更多的方法，包括 offer(),peek(),poll()等.
* Vector 跟 ArrayList 的实现类似，但是所有读写方法都实现了 synchronized
* Vector 和 ArrayList 在更多元素添加进来时会请求更大的空间。Vector 每次请求其大小的双倍空间，而 ArrayList 每次对 size 增长 50%

PS: list的add可以指定插入位置，set是覆盖指定位置。SynchronizedList 和 Vector 的区别
* Vector 使用同步方法实现，synchronizedList 使用同步代码块实现
* SynchronizedList 有很好的扩展和兼容功能。他可以将所有的 List 的子类转成线程安全的类
* SynchronizedList 在 listIterator 的时候没有枷锁，所以进行遍历时要手动进行同步处理
* SynchronizedList 可以指定锁定的对象

CopyOnWriteArrayList 和 ArrayList 的区别
* CopyOnWriteArrayList 的 add、remove 方法使用 lock 加了锁，当有新元素 add/remove 时，先从原有的数组中拷贝一份出来，然后在新的数组做写操作，写完之后，再将原来的数组引用指向到新数组
* CopyOnWriteArrayList 的迭代器支持 hasNext(), next()等不可变操作，但不支持可变 remove()等操作

Arrays.asList
* Arrays.asList 得到的只是一个 Arrays 的内部类，一个原来数组的视图 List，因此如果对它进行增删操作会报错，只能遍历，要转成其他 List 才能增删（例如 new ArrayList()）

foreach删除为什么会报错foreach编译时候会被转成迭代器，而list里头有个int属性，用来记录修改次数，获取迭代器时候会传进去。迭代器迭代时候回去判断list里这个值和迭代器里的这个值是否一致，不一样报错。如何在遍历的同时删除 ArrayList 中的元素
* 使用普通 for 循环删除（需要调整循环的下标）
* 直接使用 Iterator 的 remove 进行删除
* 使用 jdk8 中提供的 filter 过滤
* 使用 jdk8 中的 removeIf 方法
* 使用 fail-safe 的集合类（例如：ConcurrentLinkedDeque）

SetHashSet、LinkedHashSet、TreeSetHashSet
* 基于 HashMap 实现，利用 HashMap 同一个 Hash 值只能有一个 Value 的特性来实现 Set 的去重功能

LinkedHashSet
* 基于 LinkedHashMap 实现，利用 LinkedHashMap 同一个 Hash 值只能有一个 Value 的特性来实现 Set 的去重功能

TreeSet
* 基于 TreeMap 实现，利用 TreeMap 同一个 Hash 值只能有一个 Value 的特性来实现 Set 的去重功能

HashSet 和 TreeSet 的区别
* TreeSet 是红黑树实现的，Treeset 中的数据是自动排好序的，不允许放入 null 值
* HashSet 是哈希表实现的，HashSet 中的数据是无序的，可以放入 null，但只能放入一个 null
* HashSet 基于 HashMap 实现，而 TreeMap 是基于红黑树实现的
* TreeMap 会按 key 升序排序，元素在插入 TreeSet 时 compareTo()方法要被调用，所以 TreeSet 中的元素要实现 Comparable 接口

Set 如何保证元素不重复
* 当向 HashSet 中添加元素的时候，首先计算元素的 hashcode 值，然后通过扰动计算和按位与的方式计算出这个元素的存储位置，如果这个位置位空，就将元素添加进去；如果不为空，则用 equals 方法比较元素是否相等，相等就不添加，否则找一个空位添加
* TreeSet 是用元素的 compareTo()方法来判断重复元素的

Set 和 List 区别
* 都继承自 Collection
* 都是用来存储一组相同类型的元素
* List 中元素有放入顺序，元素可重复
* Set 中元素无放入顺序，元素不可重复

HashMap、HashTable、LinkedHashMap、TreeMap、ConcurrentHashMap、ConcurrentSkipListMapHashMap介绍地址JDK1.7 及 1.7 之前的版本（数组+链表）
* HashMap 实现了 Map 接口，即允许放入 key 为 null 的元素，也允许插入 value 为 null 的元素
* 采用数组+链表的方式存储数据
* 存储的对象必须实现 hashCode()和 equals()两个方法
* 写入数据时，先根据对象的 hashCode 获取数组的下标，再获取到数组中对应位置的链表（解决了 hashcode 冲突的问题，也成为拉链法），然后插入数据到链表中，equals 方法决定对象存入链表时是覆盖还是新增
* 读取数据时，先根据对象的 hashCode 获取数组的下标，再获取到数组中对应位置的链表，然后依次遍历链表，通过 equals 方法判断是否命中

JDK1.8 及 1.8 之后的版本（数组+链表+红黑树）
* 采用数组+链表+红黑树的方式存储数据
* 为什么要用红黑树：二叉查找树会退化，但是红黑树会通过左旋右旋避免
* 为了防止链表过长，当数组的长度大于 64 且链表的长度大于 8 的时候会将链表转换成红黑树（使用头结点的值来判断是否是链表，大于 0 表示是链表，如果当前数组的长度小于 64，那么会选择进行数组扩容，而不是转换为红黑树）
* 读取数据时，会根据头结点判断对应数组下标处的是链表还是红黑树，如果是链表，则遍历得到结果，如果是红黑树，执行查找得到结果
* 扩容机制：与 JDK1.7 的区别是，JDK7 是先扩容后插入新值的，JDK8 先插入新值再扩容

扩容机制JDK7使用是hash值与数组长度-1 这个掩码进行与运算，得到Entry元素的新下标位置，得到的结果直接就是下标位置 ；Jdk1.8中是使用hashcode与 数组长度 进行与运算，得到的是0 或者非零。如果是0表示新位置下标不变，如果不是0那么表示位置有变动，如果有变动下标位置是原位置加上原数组长度。
* 为什么 capacity 数组容量必须为 2^n：为了保证通过 hash 方式获取下标的时候分布均匀。数组长度为 2 的 n 次幂的时候，不同的 key 算得得 index 相同的几率较小，那么数据在数组上分布就比较均匀，也就是说碰撞的几率小，相对的，查询的时候就不用遍历某个位置上的链表，这样查询效率也就较高了。capacity 的值太小可能导致频繁发生扩容，影响效率，太大了又浪费空间，所以默认为 16
* 为什么负载因子的值默认为 0.75：加载因子是表示 Hash 表中元素的填满的程度，加载因子越大，填满的元素越多，空间利用率越高，但冲突的机会加大，反之加载因子越小，填满的元素越少，冲突的机会减小，但空间浪费多。冲突的机会越大，则查找的成本越高，反之，查找的成本越小，因此，必须在 "hash 冲突率"与"空间利用率"之间寻找一种平衡与折中，所以默认采用 0.75

HashMap 线程不安全介绍地址
1. 同时put，如果多个线程同时定位到一个链表中的同一个 index，则会导致只有一个数据插入链表成功
2. put正好需要扩容，这时另一个线程来get，由于hashmap是先创建数组，然后引用指向新数组，再rehash，所以get是get新数组，从而会出现null

Hashtable
* Hashtable 是 JDK1.0 新增的，是遗留类，项目中不应该去使用它，实现原理和 HashMap 类似，也是通过数组+链表的方式实现，但它是线程安全的，因为所有读写方法都实现了 synchronized 锁

LinkedHashMap
* LinkedHashMap 是 HashMap 的直接子类，二者唯一的区别是 LinkedHashMap 在 HashMap 的基础上，在 Entry 数组之外，采用双向链表的形式将所有 entry 连接起来，这样是为保证元素的迭代顺序跟插入顺序相同，该双向链表的迭代顺序就是 entry 的插入顺序
* 写入数据时，会先执行一次查询，数据如果已存在则直接返回，数据不存在时，按照 HashMap 的方式将数据插入到对应链表中，并将数据插入到双向链表的尾部
* 迭代 LinkedHashMap 时，不需要像 HashMap 那样遍历整个 table，而只需要直接遍历 header 指向的双向链表即可，也就是说 LinkedHashMap 的迭代时间就只跟 entry 的个数相关，而跟 table 的大小无关，所以当 Map 的数据量不大，而容量很大时，LinkedHashMap 的遍历速度比 HashMap 快
* LinkedHashMap 提供了 removeEldestEntry 方法，该方法的作用是告诉 Map 是否要删除最早插入的 Entry，如果该方法返回 True，那么最早插入的元素会被删除，在每次插入新元素的之后 LinkedHashMap 会自动询问 removeEldestEntry()是否要删除最老的元素，因此可以通过重载该方法，来实现 LRU 算法（固定大小的 FIFO 策略的缓存）

TreeMap
* TreeMap 底层通过红黑树(Red-Black tree)实现，也就意味着 containsKey(), get(), put(), remove()都有着 O(logn)的时间复杂度
* TreeMap 不允许放入 null 值
* TreeMap 中的数据是自动排好序的，TreeMap 会按 key 升序排序，元素在插入 TreeMap 时 compareTo()方法要被调用，所以 想自定义排序必须要实现 Comparable 接口

ConcurrentHashMap
* JDK1.5~1.7 版本（分段锁）：

		* ConcurrentHashMap 维护了一个 Segment 数组，将整个 Hash 表划分为多个分段
		* Segment 继承了 ReentrantLock，实现了独占模式的可重入锁，为每一个 segment 提供了线程安全的保障
		* Segment 内部是由数组+链表组成，维护了哈希散列表的若干个桶，每个桶是由 HashEntry 构成的链表，Segment 内部的数组支持扩容
		* 写入数据之前需要先获取该 Segment 的独占锁，再执行类似 HashMap 的写入逻辑
		* 读取数据时，先根据 Key 计算 hash 值，找到对应的 sgment，再根据 hash 找到 sgment 内部的数组中的对应链表，最后使用 key.equals 方法遍历链表得到结果
		* 缺点：最大并发度受 Segment 的个数限制
		* 
	* JDK1.8 及 1.8 之后的版本（数组+链表+红黑树）

		* 采用类似 JDK1.8 的 HashMap 的数据+链表+红黑树方式存储数据
		* put 时，先根据 hashcode 获取到数组下标对应的链表，如果数组对应下标的链表为空，使用 CAS 创建链表，如果链表已存在，使用 synchronized 对链表加锁，然后再插入数据
		* 为了防止链表过长，当数组的长度大于 64 且链表的长度大于 8 的时候会将链表转换成红黑树（跟 JDK8 的 HashMap 一样，使用头结点的值来判断是否是链表，大于 0 表示是链表，如果当前数组的长度小于 64，那么会选择进行数组扩容，而不是转换为红黑树）
		* 读取数据时，先根据 Key 计算 hash 值，找到数组中的对应链表，再根据头结点判断是链表或者红黑树或者正在扩容，如果是链表，则遍历得到结果，如果是红黑树，执行查找得到结果，如果正在扩容，会等待取到锁后再读取数据
		* 扩容机制：数组每次都是双倍扩容，将原来的 tab 数组的元素迁移到新的 nextTab 数组中，rehash方法就跟hashmap一样。如果有新的线程get数据，则取原数组的， put 数据，会先帮助完成扩容，再 put 数据（put、computifabsent等操作都会帮助扩容，这些操作都可能是并发的，所以concurrenthashmap也叫做多线程扩容，每个线程最少分到 16 个链表，各自处理，不会互相影响）


	* ConcurrentHashMap的读是否要加锁，为什么

不需要，get操作可以无锁是由于Node的元素val和指针next是用volatile修饰的，在多线程环境下线程A修改结点的val或者新增节点的时候是对线程B可见的。get操作全程不需要加锁是因为Node的成员val是用volatile修饰的和数组用volatile修饰没有关系。
* ConcurrentHashMap的迭代器是强一致性的迭代器还是弱一致性的迭代器?

弱一致性的迭代器，在这种迭代方式中，当iterator被创建后集合再发生改变就不再是抛出ConcurrentModificationException，取而代之的是在改变时new新的数据从而不影响原有的数据，iterator完成后再将头指针替换为新的数据，这样iterator线程可以使用原来老的数据，而写线程也可以并发的完成改变，更重要的，这保证了多个线程并发执行的连续性和扩展性，是性能提升的关键。为什么说ConcurrentHashMap是弱一致性的？ConcurrentHashMap的弱一致性体现在clear、迭代器和get方法，原因在于没有加锁。举例：迭代器在遍历数据的时候是一个Segment一个Segment去遍历的，如果在遍历完一个Segment时正好有一个线程在刚遍历完的Segment上插入数据，就会体现出不一致性。clear也是一样。get方法在取数据的时候，如果有一个线程正好在put，假设他put的key是存在的，那么get获取数据的时候可以获取到put的新值，因为HashEntry的value是volatile修饰的，所以在一个线程对其进行修改后，另一个线程可以马上看到。如果是一个新HashEntry，那么就不能马上看到，虽然HashEntry的数组 table被volatile修饰，但是这样只是代表table的引用地址如果被修改，其他线程可以立马看到，并不代表table里的数据被修改立马可以看到。ConcurrentSkipListMap
* ConcurrentSkipListMap 是一个内部使用跳跃表，并且支持排序和并发的一个 Map（treemap安全版），是线程安全的

HashMap 和 Hashtable 区别
1. 线程安全：Hashtable 是线程安全，HashMap 是非线程安全。HashMap 的性能会高于 Hashtable，Hashtable 的所有方法都实现了 synchronize 锁
2. 是否可以使用 null 作为 key：HashMap 允许将 null 作为一个 entry 的 key 或者 value，而 Hashtable 不允许
3. 继承和实现：HashTable 继承自 Dictionary 类，而 HashMap 是 Java1.2 引进的 Map interface 的一个实现
4. 计算 hash 的方法：Hashtable 计算 hash 是直接使用 key 的 hashcode 对 table 数组的长度直接进行取模，而 HashMap 计算 hash 是对 key 的 hashcode 进行了二次 hash，以获得更好的散列值，然后对 table 数组长度取模
5. 初始容量及扩容机制：HashMap 的初始容量为 16，Hashtable 初始容量为 11。HashMap 扩容时是当前容量翻倍即：capacity 2，Hashtable 扩容时是容量翻倍+1 即：capacity (2+1)
6. 遍历方式：都使用了 Iterator，但 Hashtable 还使用了 Enumeration 的方式 且用 Enumeration 时不支持 fail-fast（遍历过程中如果元素被修改会导致遍历失败，可以用 Iterator 的 remove 方法避免这种情况）
7. key 规则：HashTable 直接使用对象的 hashCode，HashMap 重新计算 hash 值

HashMap 和 ConcurrentHashMap 的区别
* 都是使用桶数组（数组+链表）实现
* 1.7 之前的 ConcurrentHashMap 对桶数组进行了分段，并且在每一个分段上都用 ReentrantLock 锁进行了保护
* 1.8 之后的 ConcurrentHashMap 采用数组+链表+红黑树的方式实现，而加锁则采用 CAS 和 synchronized 实现
* ConcurrentHashMap 支持 fail-safe （遍历过程中如果元素被修改不会有任何影响），因为 ConcurrentHashMap 的迭代器是弱一致性