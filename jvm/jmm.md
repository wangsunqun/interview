#jmm(java内存模型)

## happen-before
jmm中定义的两项操作之间的偏序关系，如果操作A先行发生于操作B，那么操作A产生的影响能够被操作B观察到。   
Java内存模型中存在的天然的先行发生关系：   
1. 程序次序规则：同一个线程内，按照代码出现的顺序，前面的代码先行于后面的代码，准确的说是控制流顺序，因为要考虑到分支和循环结构。   
2. 管程锁定规则：一个unlock操作先行发生于后面（时间上）对同一个锁的lock操作。   
3. volatile变量规则：对一个volatile变量的写操作先行发生于后面（时间上）对这个变量的读操作。   
4. 线程启动规则：Thread的start( )方法先行发生于这个线程的每一个操作。   
5. 线程终止规则：线程的所有操作都先行于此线程的终止检测。可以通过Thread.join( )方法结束、Thread.isAlive( )的返回值等手段检测线程的终止。    
6. 线程中断规则：对线程interrupt( )方法的调用先行发生于被中断线程的代码检测到中断事件的发生，可以通过Thread.interrupt( )方法检测线程是否中断   
7. 对象终结规则：一个对象的初始化完成先行于发生它的finalize（）方法的开始。   
8. 传递性：如果操作A先行于操作B，操作B先行于操作C，那么操作A先行于操作C。   

总结：一个操作“时间上的先发生”不代表这个操作先行发生；一个操作先行发生也不代表这个操作在时间上是先发生的（重排序的出现）。时间上的先后顺序对先行发生没有太大的关系，所以衡量并发安全问题的时候不要受到时间顺序的影响，一切以先行发生原则为准。  

## volatile 
volatile并不是说线程直接读取主内存的值，而是当一个线程修改了工作内存的值，它会立即同步到主内存（没有用这个关键字并不是立即同步，而是看CPU），然后cpu总线嗅探机制会让其他核（线程)的工作内存里的值失效，这样就可以重新去主内存拉取最新值  
主内存：内存条  
工作内存：cpu寄存器或者高速缓存  
![](../resources/jmm.jpg)

### 嗅探机制工作原理
每个处理器通过监听在总线上传播的数据来检查自己的缓存值是不是过期了，如果处理器发现自己缓存行对应的内存地址修改，就会将当前处理器的缓存行设置无效状态，当处理器对这个数据进行修改操作的时候，会重新从主内存中把数据读到处理器缓存中。  
### 总线风暴
如果用了太多volatile，会不断嗅探（cas）总线导致总线带宽达到峰值。
### 伪共享：
这里一、二、三级缓存都是由缓存行组成，一个缓存行是64byte大小。伪共享的意思是，一个缓存行存多个属性，但是cpu都是以缓存行为单位执行的，这时候由于总线嗅探机制，会导致一个缓存行数据都失效，即使这个缓存行里只有一个属性有变化。解决方法：用@Contended注解，这个注解会自动为属性填充，使一个缓存行只有一个属性  

PS: 寄存器和一级二级缓存都在cpu里，三级在外面  
![](../resources/jmm1.jpg)

### 指令重排
在单线程下无所谓，但是在多线程可能就会造成问题

### 内存屏障
#### 硬件层的内存屏障
分为两种：Load Barrier 和 Store Barrier即读屏障和写屏障。  
内存屏障有两个作用：
1. 阻止屏障两侧的指令重排序；
2. 强制把写缓冲区/高速缓存中的脏数据等写回主内存，让缓存中相应的数据失效。

（站在告诉缓存角度理解）  
对于Load Barrier来说，在指令前插入Load Barrier，可以让高速缓存中的数据失效，强制重新从主内存加载数据；  
对于Store Barrier来说，在指令后插入Store Barrier，能让写入缓存中的最新数据更新写入主内存，让其他线程可见。  

#### Java内存屏障  
简单来说就是在屏障前后不能重排序  
* java的内存屏障通常所谓的四种即LoadLoad,StoreStore,LoadStore,StoreLoad实际上也是上述两种的组合，完成一系列的屏障和数据同步功能。
* LoadLoad屏障：对于这样的语句Load1; LoadLoad; Load2，在Load2及后续读取操作要读取的数据被访问前，保证Load1要读取的数据被读取完毕。
* StoreStore屏障：对于这样的语句Store1; StoreStore; Store2，在Store2及后续写入操作执行前，保证Store1的写入操作对其它处理器可见。
* LoadStore屏障：对于这样的语句Load1; LoadStore; Store2，在Store2及后续写入操作被刷出前，保证Load1要读取的数据被读取完毕。
* StoreLoad屏障：对于这样的语句Store1; StoreLoad; Load2，在Load2及后续所有读取操作执行前，保证Store1的写入对所有处理器可见。它的开销是四种屏障中最大的。在大多数处理器的实现中，这个屏障是个万能屏障，兼具其它三种内存屏障的功能

#### volatile 
语义中的内存屏障
* volatile的内存屏障策略非常严格保守，非常悲观且毫无安全感的心态：

在每个volatile写操作前插入StoreStore屏障，在写操作后插入StoreLoad屏障；在每个volatile读操作前插入LoadLoad屏障，在读操作后插入LoadStore屏障；
* 内存屏障的作用，避免了volatile变量和其它指令重排序(作用1)、线程之间实现了通信(作用2)，使得volatile表现出了锁的特性。


